---
title: "Researcher Variability in Replications: Replication File, Step 2"
output: html_notebook
---

|Metric|Definition|Measure|
|------|----------|---------|
|*Verification* (verif)| The direction of the regression coefficient is the same as the original & either within 0.05 absolute difference or the same significance at p<0.05 threshold|1=verified, 0=not|
|*Exact Verification* (exact)|The value of the replication odd-ratio is identical to the second decimal place of the original|1=exact, 0=not|
|*Replication Deviance* (deviance_abs)|The absolute deviation of the replication from the original|continuous measure starting from exact (=0) and increasing positive values|

```{r setup}
rm(list = ls())
library(pacman)


pacman::p_load("dplyr", "readr", "lattice", "tidyr", "readxl", "knitr", "boot", "ragg", "kableExtra", "ggpubr","lme4", "jtools","sjPlot", "sjmisc", "sjlabelled", "rvest", "lavaan", "lavaanPlot", "see")


```


```{r setup2}
# load data from 01_Data_Prep
load(file = "data/data.Rdata")

#remove original study from data
cri_long <- subset(cri_long, insamp == 1)
cri_cur_long <- subset(cri_cur_long, insamp == 1)

# Team 33 missing data on stat degree, code to 0
cri_cur_long$stat_degree <- ifelse(is.na(cri_cur_long$stat_degree), 0, cri_cur_long$stat_degree)

# Make soc degree variable (versus Poli Sci and Other)
cri_cur_long$degree_soc <- ifelse(is.na(cri_cur_long$degree), 3, cri_cur_long$degree)

cri_cur_long$degree_soc <- ifelse(cri_cur_long$degree_soc == 1, 1, 0)

cri_long$degree_soc <- ifelse(is.na(cri_long$degree), 3, cri_long$degree)

cri_long$degree_soc <- ifelse(cri_long$degree_soc == 1, 1, 0)

# disable scientific notation
options(scipen = 999)
```


A total of `r sum(cri_long$insamp, na.rm = T)` results from `r length(unique(cri_long$u_teamid)) - 2` teams

## Figure 1




```{r fig1}



plot1 <- ggplot(cri_long, aes(x = count, y = deviance_abs, color = Exp1, shape = Exp1)) +
  geom_point(size = 2.5) + 
  coord_cartesian(ylim=c(0, 0.5)) +
  ylab("Replicated Effect\n(deviance from original)") +
  scale_color_manual(values = c("#009E73","#D55E00"), name = "Replication Group", labels = c("Transparent","Opaque")) +
  scale_shape_manual(values = c(6,2)) +
  theme(axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_text(size = 12, color = "black"),
        axis.line.x = element_line(),
        axis.line.y = element_line(),
        legend.position = "none",
        plot.background = element_blank(),
        panel.background = element_blank(),
        legend.background = element_blank(),
        legend.key = element_blank(),
        legend.text = element_text(size = 11)) +
  guides(color = guide_legend(override.aes = list(shape = c(19,19), size=5, fill = NA)), shape = F)


# get means to add
mean0 <- round(mean(cri_long$deviance_abs[cri_long$Exp1 == 0], na.rm = T),3)
mean1 <- round(mean(cri_long$deviance_abs[cri_long$Exp1 == 1], na.rm = T),3)

plot2 <- ggboxplot(cri_long, "Exp1","deviance_abs", color = "Exp1", 
                   whisklty = 0, palette = c("#009E73","#D55E00"), 
                   outlier.shape = NA, size = 1) +
  coord_cartesian(ylim=c(0, 0.04)) +
  xlab("Group") +
  scale_fill_discrete(name = "Replication Group", labels = c("Transparent","Opaque")) +
  annotate(geom="text", x=1.1, y=0.0145, label = paste0("mean"),
              color="#009E73", size = 3, hjust = 0) + 
  annotate(geom="text", x=2.1, y=0.036, label = paste0("mean"),
              color="#D55E00", size = 3, hjust = 0) +
  annotate(geom="text", x=1.1, y=0.013, label = paste0("deviance"),
              color="#009E73", size = 3, hjust = 0) + 
  annotate(geom="text", x=2.1, y=0.0345, label = paste0("deviance"),
              color="#D55E00", size = 3, hjust = 0) +
  annotate(geom="text", x=1.1, y=0.011, label = paste0(mean1),
              color="#009E73", size = 3, hjust = 0, fontface = 2) + 
  annotate(geom="text", x=2.1, y=0.0325, label = paste0(mean0),
              color="#D55E00", size = 3, hjust = 0, fontface = 2) +
  theme(axis.title.y = element_blank(),
        legend.position = "bottom",
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_text(size = 12),
        plot.margin = margin(2,2,2,2),
        legend.text = element_text(size = 11))

plotF <- ggarrange(plot1,NA,plot2, ncol = 3, widths = c(7,1,7), common.legend = T, legend = "bottom")
agg_png(filename = "results/Fig1.png", res = 144, width = 900)
plotF
dev.off()

knitr::include_graphics("results/Fig1.png")
```
## Table 2

### Setup

```{r table2}

# start with descriptive table

desc <- as.data.frame(matrix(nrow = 17, ncol = 11))

desc[1,] <- c("","","Means by Sample","","","Pear. Correlations w/ Raw Results","","","","","")

desc[2,] <- c("Variables","Measurement","Transparent","Opaque", "Pooled", "Verification", "Exact Verif.", "Deviance", "", "", "")

desc[,1] <- c("", "Variables","Raw Replication Results", "Verification", "Exact Verification", "Deviance", "Curated Replication Results", "Verification", "Exact Verification", "Deviance", "Independent Variables", "Stata", "Sociology Degree", "Stats-Skill", "Difficulty", "Team Size", "Transparent")

desc[,2] <- c("", "Measurement","", "same direction =1","identical at two decimals =1", "absolute difference with original","", "same direction =1","identical at two decimals =1", "absolute difference with original","", "other software =0","other degrees =0","4-question scale, stdzd,","1-question, stdzd.","1-3 persons","Transparent group =1")

# fill in transparent group results

desc[3:17,3] <- c("", 
                  mean(cri_long$verif[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$exact[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$deviance_abs[cri_long$Exp1 == 1], na.rm = T),
                  "",
                  mean(cri_cur_long$verif[cri_cur_long$Exp1 == 1], na.rm = T),
                  mean(cri_cur_long$exact[cri_cur_long$Exp1 == 1], na.rm = T),
                  mean(cri_cur_long$deviance_abs[cri_cur_long$Exp1 == 1], na.rm = T),
                  "",
                  mean(cri_long$stata[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$degree_soc[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$stat_skill[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$difficult[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$numinteam[cri_long$Exp1 == 1], na.rm = T),
                  1)

# opaque

desc[3:17,4] <- c("", 
                  mean(cri_long$verif[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$exact[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$deviance_abs[cri_long$Exp1 == 0], na.rm = T),
                  "",
                  mean(cri_cur_long$verif[cri_cur_long$Exp1 == 0], na.rm = T),
                  mean(cri_cur_long$exact[cri_cur_long$Exp1 == 0], na.rm = T),
                  mean(cri_cur_long$deviance_abs[cri_cur_long$Exp1 == 0], na.rm = T),
                  "",
                  mean(cri_long$stata[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$degree_soc[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$stat_skill[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$difficult[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$numinteam[cri_long$Exp1 == 0], na.rm = T),
                  0)

# pooled

desc[3:17,5] <- c("", 
                  mean(cri_long$verif, na.rm = T),
                  mean(cri_long$exact, na.rm = T),
                  mean(cri_long$deviance_abs, na.rm = T),
                  "",
                  mean(cri_cur_long$verif, na.rm = T),
                  mean(cri_cur_long$exact, na.rm = T),
                  mean(cri_cur_long$deviance_abs, na.rm = T),
                  "",
                  mean(cri_long$stata, na.rm = T),
                  mean(cri_long$degree_soc, na.rm = T),
                  mean(cri_long$stat_skill, na.rm = T),
                  mean(cri_long$difficult, na.rm = T),
                  mean(cri_long$numinteam, na.rm = T),
                  mean(as.numeric(cri_long$u_expgroup1), na.rm = T))




```

### Make Table

```{r tbl2corr, warning = F, message = F}
cri_long <- cri_long %>%
  ungroup()
cri_cur_long <- cri_cur_long %>%
  ungroup()


desc_c1 <- select(cri_long, verif, exact, deviance_abs, stata, degree_soc, stat_skill, difficult, numinteam, u_expgroup1)

desc_c1$u_expgroup1 <- as.numeric(desc_c1$u_expgroup1)

cor1 <- as.data.frame(cor(desc_c1, use = "pairwise"))

desc_c2 <- select(cri_cur_long, verif, exact, deviance_abs, stata, degree_soc, stat_skill, difficult, numinteam, u_expgroup1)

desc_c2$u_expgroup1 <- as.numeric(desc_c2$u_expgroup1)

cor2 <- as.data.frame(cor(desc_c2, use = "pairwise"))

# test for sig of corrs

test1 <- psych::corr.test(desc_c1)
test2 <- psych::corr.test(desc_c2)

test1df <- as.data.frame(round(test1[["p"]],3))[4:9,1:3]
test2df <- as.data.frame(round(test2[["p"]],3))[4:9,1:3]

# we drop 'other' as a degree because it does not have enough of any one degree type to be meaningful, and thus we just compare sociology and political science

desc_c1a <- subset(cri_long, degree != 3, select = c(verif, exact, deviance_abs, degree))
desc_c2a <- subset(cri_cur_long, degree != 3, select = c(verif, exact, deviance_abs, degree))

test1a <- psych::corr.test(desc_c1a)
test2a <- psych::corr.test(desc_c2a)

test1adfr <- as.data.frame(round(test1a[["r"]],3))[4,1:3]
test2adfr <- as.data.frame(round(test2a[["r"]],3))[4,1:3]

test1adfp <- as.data.frame(round(test1a[["p"]],3))[4,1:3]
test2adfp <- as.data.frame(round(test2a[["p"]],3))[4,1:3]

# update p value table with adjusted scores for degree

test1df[2,1:3] <- test1adfp
test2df[2,1:3] <- test2adfp

# add correlations to table

desc[4:6,6:8] <- cor1[1:3,1:3]

desc[12:17,6:8] <- cor1[4:9,1:3]

desc[8:10,9:11] <- cor2[1:3,1:3]

desc[12:17,9:11] <- cor2[4:9,1:3]

# add adjusted degree correlations
desc[13,6:8] <- test1adfr
desc[13,9:11] <- test2adfr

write.csv(desc, file = "results/Tbl2.csv")

cri_agg <- aggregate(cri_long, by = list(cri_long$u_teamid), FUN = mean)
cri_cur_agg <- aggregate(cri_cur_long, by = list(cri_cur_long$u_teamid), FUN = mean)

rm(test1, test2, test1a, test2a, test1df, test2df, test1adfp, test2adfp, test1adfr, test2adfr)
```


## Explaining Variance

Our observations take place only at the team level, therefore it is only necessary to run a regression on the team averages ('level-2') of the three outcome variables *verif*, *exact* and *deviance_abs*.

Aggregate data to team-level

```{r aggregate_team}
# curated
cri_team <- cri_cur_long %>%
  mutate(u_expgroup1 = as.numeric(u_expgroup1)) %>%
  group_by(u_teamid2) %>%
  summarize(verif_m = mean(verif, na.rm = T),
            verif_sd = sd(verif, na.rm = T),
            exact_m = mean(exact, na.rm = T),
            exact_sd = sd(exact, na.rm = T),
            dev_m = mean(deviance_abs, na.rm = T),
            dev_sd = sd(deviance_abs, na.rm = T),
            stata = mean(stata, na.rm = T),
            degree = mean(degree, na.rm = T),
            stat_skill = mean(stat_skill, na.rm = T),
            numinteam = mean(numinteam, na.rm = T),
            exp = mean(u_expgroup1, na.rm = T),
            difficult = mean(difficult, na.rm = T))

cri_team_orig <- cri_long %>%
  group_by(u_teamid2) %>%
  mutate(u_expgroup1 = as.numeric(u_expgroup1)) %>%
  summarize(verif_m = mean(verif, na.rm = T),
            verif_sd = sd(verif, na.rm = T),
            exact_m = mean(exact, na.rm = T),
            exact_sd = sd(exact, na.rm = T),
            dev_m = mean(deviance_abs, na.rm = T),
            dev_sd = sd(deviance_abs, na.rm = T),
            stata = mean(stata, na.rm = T),
            degree = mean(degree, na.rm = T),
            stat_skill = mean(stat_skill, na.rm = T),
            numinteam = mean(numinteam, na.rm = T),
            exp = mean(u_expgroup1, na.rm = T),
            difficult = mean(difficult, na.rm = T))

cri_team$degree <- factor(cri_team$degree, labels = c("Sociology", "Political Science", "Other"))
cri_team_orig$degree <- factor(cri_team_orig$degree, labels = c("Sociology", "Political Science", "Other"))

# trim outlier
cri_team$stat_skill <- ifelse(cri_team$stat_skill < -4, -4, cri_team$stat_skill)
cri_team_orig$stat_skill <- ifelse(cri_team_orig$stat_skill < -4, -4, cri_team_orig$stat_skill)




```
Variance decomposition

```{r decomp}
# curated
mlm01_verif <- glmer(verif ~ (1 | u_teamid2), family = binomial, data = cri_cur_long)

mlm11_exact <- glmer(exact ~ (1 | u_teamid2), family = binomial, data = cri_cur_long)

mlm21_deviance <- lmer(deviance_abs ~ (1 | u_teamid2), data = cri_cur_long)

# original
mlm01_verif_orig <- glmer(verif ~ (1 | u_teamid2), family = binomial, data = cri_long)

mlm11_exact_orig <- glmer(exact ~ (1 | u_teamid2), family = binomial, data = cri_long)

mlm21_deviance_orig <- lmer(deviance_abs ~ (1 | u_teamid2), data = cri_long)

tab_model(mlm01_verif, mlm01_verif_orig, mlm11_exact, mlm11_exact_orig, mlm21_deviance, mlm21_deviance_orig,show.ci = F, file = "results/mlm.htm")

mlm <- as.data.frame(read_html("results/mlm.htm") %>% html_table(fill=TRUE))
  
```

Variance decomposition reveals that of the total variance, `r paste0(100*(as.numeric(mlm$verif[mlm$Var.1 == "ICC"])),"%")` of *Verification*, `r paste0(100*(as.numeric(mlm$exact[mlm$Var.1 == "ICC"])),"%")` of *Exact Verification*, and `r paste0(100*(as.numeric(mlm$deviance_abs[mlm$Var.1 == "ICC"])),"%")` of *Replication Deviance* occurs between-teams (as opposed to within-teams).




### Variance Plots

```{r var_plot}
cri_cur_long <- cri_cur_long %>%
  mutate(degreeF = as.factor(degree),
         stataF = as.factor(stata),
         stat_skillF = as.factor(ifelse(stat_skill > 0, 1, 0)),
         dev_abs_log = log(deviance_abs+0.001),
         dev_abs_min = min(dev_abs_log, na.rm = T),
         dev_abs_log_c = dev_abs_log - dev_abs_min)

# alt summary stats by group
cri_sum_plot <- cri_cur_long %>%
  group_by(degree) %>%
  summarise(dev_degree = mean(deviance_abs, na.rm = T),
            dev_degree_sd = sd(deviance_abs, na.rm = T),
            dev_degree_n = n())

cri_sum_plot2 <- cri_cur_long %>%
  group_by(stataF, u_expgroup1) %>%
  summarise(dev_stataex = mean(deviance_abs, na.rm = T),
            dev_stataex_sd = sd(deviance_abs, na.rm = T),
            dev_stataex_n = n())  

cri_sum_plot3 <- cri_cur_long %>%
  group_by(stat_skillF) %>%
  summarise(dev_stat = mean(deviance_abs, na.rm = T),
            dev_stat_sd = sd(deviance_abs, na.rm = T),
            dev_stat_n = n())

cri_sum_plot$degree <- as.factor(cri_sum_plot$degree)
cri_sum_plot2$stataF <- as.factor(cri_sum_plot2$stataF)
cri_sum_plot3$stat_skillF <- as.factor(cri_sum_plot3$stat_skillF)

```



```{r bar1}
ggplot(cri_sum_plot) +
  geom_bar(aes(y=dev_degree, x=degree, fill=degree), stat = 'identity') +
  geom_errorbar(aes(x=degree, ymin=dev_degree-(dev_degree_sd/sqrt(dev_degree_n)), ymax = dev_degree+(dev_degree_sd/sqrt(dev_degree_n)), fill=degree)) +
  coord_flip() +
  scale_fill_manual(values = c("#D55E00","#009E73","goldenrod")) +
  annotate(geom="text", x=2.8, y=0.001, label = paste0("Other"),
              color="black", size = 4, hjust = 0) +
  annotate(geom="text", x=1.8, y=0.001, label = paste0("Political Science"),
              color="black", size = 4, hjust = 0) +
  annotate(geom="text", x=0.8, y=0.001, label = paste0("Sociology"),
              color="black", size = 4, hjust = 0) +
  ylab(label = "Deviance from Original Results") +
  theme_classic() +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  )
```


```{r bar2}
cri_sum_plot2[,1] <- as.factor(c(1,3,2,4))

agg_png(filename = "results/Fig2.png", width = 800, height = 600, res = 144)
ggplot(cri_sum_plot2) +
  geom_bar(aes(y=dev_stataex, x=stataF, fill=stataF), stat = 'identity') +
  geom_errorbar(aes(x=stataF, ymin=dev_stataex-(dev_stataex_sd/sqrt(dev_stataex_n)), ymax = dev_stataex+(dev_stataex_sd/sqrt(dev_stataex_n)), width = 0.4)) +
  coord_flip() +
  scale_fill_manual(values = c("#D55E00","#009E73","goldenrod","mediumturquoise")) +
  geom_label(aes(x=3.8, y=0.0005, label = "Stata"), fill = "white",
              color="black", label.size = NA, hjust = 0, label.r = unit(0, "lines")) +
  geom_label(aes(x=2.8, y=0.0005, label = "Other"), fill = "white",
              color="black", label.size = NA, hjust = 0, label.r = unit(0, "lines")) +
  geom_label(aes(x=1.8, y=0.0005, label = "Stata"), fill = "white",
              color="black", label.size = NA, hjust = 0, label.r = unit(0, "lines")) +
  geom_label(aes(x=0.8, y=0.0005, label = "Other"), fill = "white",
              color="black", label.size = NA, hjust = 0, label.r = unit(0, "lines")) +
  annotate(geom = "text", label = "Transparent Group", y = -0.001, x = 3.5, angle = 90, vjust = 0) +
  annotate(geom = "text", label = "Opaque Group", y = -0.001, x = 1.5, angle = 90, vjust = 0) +
  geom_vline(xintercept = 2.5, color = "grey23") +
  ylab(label = "Deviance from Original Results") +
  theme_classic() +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank()
  )
dev.off()

knitr::include_graphics("results/Fig2.png")
```


```{r var_plot2}
ggplot(cri_cur_long, aes(y=deviance_abs, x=degreeF, fill=degreeF)) +
  coord_flip(ylim = c(0,0.02)) +
  #coord_cartesian(ylim = c(0,0.15)) +
  geom_violinhalf() +
  theme_classic() +
  ylab(label = "Replicated Effect Deviance (logged)") +
  scale_fill_manual(values = c("#D55E00","#009E73","goldenrod")) +
  annotate(geom="text", x=2.9, y=0.001, label = paste0("Other"),
              color="goldenrod", size = 4, hjust = 0) +
  annotate(geom="text", x=1.9, y=0.001, label = paste0("Political Science"),
              color="#009E73", size = 4, hjust = 0) +
  annotate(geom="text", x=0.9, y=0.001, label = paste0("Sociology"),
              color="#D55E00", size = 4, hjust = 0) +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank()
  )

```
```{r var_plot3}
ggplot(cri_cur_long, aes(y=deviance_abs, x=stataF, fill=stataF)) +
  coord_flip(ylim = c(0,0.02)) +
  #coord_cartesian(ylim = c(0,0.15)) +
  geom_violinhalf() +
  theme_classic() +
  ylab(label = "Replicated Effect Deviance (logged)") +
  scale_fill_manual(values = c("#D55E00","#009E73")) +
  annotate(geom="text", x=1.9, y=0.001, label = paste0("Stata"),
              color="#009E73", size = 4, hjust = 0) +
  annotate(geom="text", x=0.9, y=0.001, label = paste0("Other"),
              color="#D55E00", size = 4, hjust = 0) +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank()
  )

```
```{r var_plot4}
ggplot(cri_cur_long, aes(y=deviance_abs, x=stat_skillF, fill=stat_skillF)) +
  coord_flip(ylim = c(0,0.02)) +
  #coord_cartesian(ylim = c(0,0.15)) +
  geom_violinhalf() +
  theme_classic() +
  ylab(label = "Replicated Effect Deviance (logged)") +
  scale_fill_manual(values = c("#D55E00","#009E73")) +
  annotate(geom="text", x=1.9, y=0.001, label = paste0("Less Stats Skills/Experience"),
              color="#009E73", size = 4, hjust = 0) +
  annotate(geom="text", x=0.9, y=0.001, label = paste0("More Stats Skills/Experience"),
              color="#D55E00", size = 4, hjust = 0) +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank()
  )

```

These regressions are interesting

### Regressions predicting within-team variance **curated**

```{r varexp}


# variables, researcher aspects

# MEANS
m01_verif_mean <- lm(verif_m ~ exp + stata + stat_skill , data = cri_team)

m11_exact_mean <- lm(exact_m ~ exp + stata + stat_skill , data = cri_team)

m21_deviance_mean <- lm(dev_m ~ exp + stata + stat_skill , data = cri_team)

#SDs
m001_verif_sd <- lm(verif_sd ~ exp + stata + stat_skill , data = cri_team)

m011_exact_sd <- lm(exact_sd ~ exp + stata + stat_skill , data = cri_team)

m021_deviance_sd <- lm(dev_sd ~ exp + stata + stat_skill , data = cri_team)


# unimportant criteria

# MEANS
m02_verif_mean <- lm(verif_m ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team)

m12_exact_mean <- lm(exact_m ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team)

m22_deviance_mean <- lm(dev_m ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team)

#SDs
m002_verif_sd <- lm(verif_sd ~ exp + stata + stat_skill  + difficult, data = cri_team)

m012_exact_sd <- lm(exact_sd ~ exp + stata + stat_skill  + difficult, data = cri_team)

m022_deviance_sd <- lm(dev_sd ~ exp + stata + stat_skill  + difficult, data = cri_team)


# difficulty

# MEANS
m03_verif_mean <- lm(verif_m ~ exp + stata + stat_skill + degree + numinteam + difficult + exp, data = cri_team)

m13_exact_mean <- lm(exact_m ~ exp + stata + stat_skill + degree + numinteam + difficult + exp, data = cri_team)

m23_deviance_mean <- lm(dev_m ~ exp + stata + stat_skill + degree + numinteam + difficult + exp, data = cri_team)

#SDs
m003_verif_sd <- lm(verif_sd ~ exp + stata + stat_skill  + difficult + exp, data = cri_team)

m013_exact_sd <- lm(exact_sd ~ exp + stata + stat_skill  + difficult + exp, data = cri_team)

m023_deviance_sd <- lm(dev_sd ~ exp + stata + stat_skill  + difficult + exp, data = cri_team)



```

### Regressions predicting within-team variance **original**

```{r varexp_orig}


# variables, researcher aspects

# MEANS
m01_verif_mean_orig <- lm(verif_m ~ exp + stata + stat_skill , data = cri_team_orig)

m11_exact_mean_orig <- lm(exact_m ~ exp + stata + stat_skill , data = cri_team_orig)

m21_deviance_mean_orig <- lm(dev_m ~ exp + stata + stat_skill , data = cri_team_orig)

#SDs
m001_verif_sd_orig <- lm(verif_sd ~ exp + stata + stat_skill , data = cri_team_orig)

m011_exact_sd_orig <- lm(exact_sd ~ exp + stata + stat_skill , data = cri_team_orig)

m021_deviance_sd_orig <- lm(dev_sd ~ exp + stata + stat_skill , data = cri_team_orig)


# Unimportant criteria

# MEANS
m02_verif_mean_orig <- lm(verif_m ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team_orig)

m12_exact_mean_orig <- lm(exact_m ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team_orig)

m22_deviance_mean_orig <- lm(dev_m ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team_orig)

#SDs
m002_verif_sd_orig <- lm(verif_sd ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team_orig)

m012_exact_sd_orig <- lm(exact_sd ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team_orig)

m022_deviance_sd_orig <- lm(dev_sd ~ exp + stata + stat_skill  + degree + numinteam, data = cri_team_orig)


# Difficulty

# MEANS
m03_verif_mean_orig <- lm(verif_m ~ exp + stata + stat_skill + degree + numinteam + difficult + exp, data = cri_team_orig)

m13_exact_mean_orig <- lm(exact_m ~ exp + stata + stat_skill + degree + numinteam + difficult + exp, data = cri_team_orig)

m23_deviance_mean_orig <- lm(dev_m ~ exp + stata + stat_skill + degree + numinteam + difficult + exp, data = cri_team_orig)

#SDs
m003_verif_sd_orig <- lm(verif_sd ~ exp + stata + stat_skill  + difficult + exp, data = cri_team_orig)

m013_exact_sd_orig <- lm(exact_sd ~ exp + stata + stat_skill  + difficult + exp, data = cri_team_orig)

m023_deviance_sd_orig <- lm(dev_sd ~ exp + stata + stat_skill  + difficult + exp, data = cri_team_orig)

```

```{r cor}
cor <- select(cri_team, verif_m, exact_m, dev_m, stata, stat_skill, difficult)
cor1 <- cor(cor, use = "pairwise.complete.obs")

cor_orig <- select(cri_team_orig, verif_m, exact_m, dev_m, stata, stat_skill, difficult)
cor1_orig <- cor(cor_orig, use = "pairwise.complete.obs")

```


### Regression Tables Curated
```{r regtbl}
tab_model(m01_verif_mean, m02_verif_mean, m03_verif_mean, p.threshold = c(0.1, 0.05, 0.01), p.style = "star", show.ci = F)

tab_model(m11_exact_mean, m12_exact_mean, m13_exact_mean, p.threshold = c(0.1, 0.05, 0.01), p.style = "star", show.ci = F)


tab_model(m21_deviance_mean, m22_deviance_mean, m23_deviance_mean, p.threshold = c(0.1, 0.05, 0.01), p.style = "star", show.ci = F)

```

### Regression Tables Original
```{r regtbl_orig}
tab_model(m01_verif_mean_orig, m02_verif_mean_orig, m03_verif_mean_orig, p.threshold = c(0.1, 0.05, 0.01), p.style = "star", show.ci = F)


tab_model(m11_exact_mean_orig, m12_exact_mean_orig, m13_exact_mean_orig, p.threshold = c(0.1, 0.05, 0.01), p.style = "star", show.ci = F)


tab_model(m21_deviance_mean_orig, m22_deviance_mean_orig, m23_deviance_mean_orig, p.threshold = c(0.1, 0.05, 0.01), p.style = "star", show.ci = F)

```

### Indirect Effects

There are clearly effects of these through perceived difficulty

```{r diff_dv}
m1_diff <- lm(difficult ~ stata + stat_skill, data = cri_team)

m1_diff_orig <- lm(difficult ~ stata + stat_skill, data = cri_team_orig)

tab_model(m1_diff, m1_diff_orig, p.threshold = c(0.1, 0.05, 0.01), p.style = "star", show.ci = F)
```

### SEM

```{r sem}
m1 <- 'verif_m ~ exp + stata + stat_skill'
m2 <- 'verif_m ~ exp + stata + stat_skill + difficult'
m3 <- 'verif_m ~ exp + a2*stata + b2*stat_skill + m*difficult
       difficult ~ a1*stata + b1*stat_skill
       # total effects
         total_stata := a2 + (a1*m)
         total_stat_skill := b2 + (b1*m)
       # indirect effects
         indir_stata := a1*m
         indir_stat_skill := b1*m'

m1fit <- sem(m1, data = cri_team_orig)
m2fit <- sem(m2, data = cri_team_orig)
m3fit <- sem(m3, data = cri_team_orig)

m1out <- summary(m1fit, fit.measures = T)
m2out <- summary(m2fit, fit.measures = T)
m3out <- summary(m3fit, fit.measures = T)

# not really ideal for showing all features of the model
# lavaanPlot(model = m3fit, coefs = T, stand = T, sig = 1.00)

# m1out[["FIT"]][["aic"]]
```


### Plotting the model

What led to mistakes - lack of transparency, working in the same software as the original - some kind of procedural similarity that is unique to softwares. 

Show all three models and their fit statistics, then plot the direct and indirect effects.

```{r}


```


### Predict routine v. non-routine


