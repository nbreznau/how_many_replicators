---
title: "Tables and Figures"
output: html_document
---

|Metric|Definition|Measure|
|------|----------|---------|
|*Verification* (verif)| The direction of the regression coefficient is the same as the original & either within 0.05 absolute difference or the same significance at p<0.05 threshold|1=verified, 0=not|
|*Exact Replication* (exact)|The value of the replication odd-ratio is identical to the second decimal place of the original|1=exact, 0=not|
|*Replication Error* (deviance_abs)|The absolute deviation of the replicated odd-ratio from the original odds-ratio | continuous measure starting from exact (=0) and increasing in positive values to measure the error |

```{r setup, warning = F, message = F}
rm(list = ls())
library(pacman)


pacman::p_load("dplyr", "readr", "lattice", "tidyr", "readxl", "knitr", "boot", "ragg", "kableExtra", "ggpubr","lme4", "jtools","sjPlot", "sjmisc", "sjlabelled", "rvest", "lavaan", "lavaanPlot", "see", "ggtext", "specr", "ggtext")

```


```{r setup2, warning = F, message = F}
# load data from 01_Data_Prep
load(file = here::here("data","data.Rdata"))


# disable scientific notation
options(scipen = 999)
```

## Test for Successful Randomization

We compare means on key variables between the two experimental groups.

```{r rct, warning = F, message = F}
t_rct <- matrix(nrow = 4, ncol = 2)
colnames(t_rct) <- c("Attribute", "ttest_p")
# make a Stata variable for the wide form
cri2 <- cri %>%
  mutate(stata = ifelse(software_final_models == "Stata", 1, 0))
t_rct[4,2] <- round(t.test(numinteam ~ u_expgroup1, data = cri2)[["p.value"]],2)
t_rct[3,2] <- round(t.test(stat_skill ~ u_expgroup1, data = cri2)[["p.value"]],2)
t_rct[2,2] <- round(t.test(degree ~ u_expgroup1, data = cri2)[["p.value"]],2)
t_rct[1,2] <- round(t.test(stata ~ u_expgroup1, data = cri2)[["p.value"]],2)

t_rct[,1] <- c("Number in Team","Stat Skill","Degree","Stata")
rm(cri2)

kable_styling(kable(t_rct, caption = "Test for Random Assignment\n(NHST t-test of likelihood of observing these data if there is no difference between group means)", format = "html"))
```


A total of `r sum(cri_long$insamp, na.rm = T)` results from `r length(unique(cri_long$u_teamid))` teams

## Figure 1

This plots how many replicators it would take to achieve replication reliability defined as the minimum number of replicators to result in a majority coming to the correct answer (here a verification) at a confidence level of 95%. 

We calculate *P* as the probability that X=x (that a replicator will get the correct answer more than 50% of the time; for simplicity we assign 51% to x)

$P(X=x)=(\frac{n}{x}) p^x(1-p)^{(n-x)}$

Then we calculate n for different values of P and p. 

First we need to map values of *x* for *n* trials (so that *x* is always at least 51% of n). We do this in a matrix to make plotting of the figure easy.

```{r fig1_prep}
# calculate x for each value of n
# use a simple 25 n by 25 x matrix

fig1 <- data.frame(n = rep(1:25,25))
fig1 <- data.frame(fig1[order(fig1$n),])
colnames(fig1) <- c("n")
fig1$x <- rep(1:25,25)

fig1 <- fig1 %>%
  mutate(x_t = round(n/1.99,0),
         x_min = ifelse(n/x_t == 2, x_t + 1, x_t),
         x = ifelse(x < x_min, x_min, x), # remove cases where x is less than 51%
         p_75 = 1-pbinom(x-1,n,0.75)) # compute cumulative probability of all values less than x, then subtract this from 1 to get all values greater than or equal to x

#loop to generate columns for remaining values of p
for (p in 76:99) {
fig1 <- fig1 %>%
  mutate(hold = 1-pbinom(x-1,n,p/100))

assign(paste0("p_",p), data.frame(fig1$hold))

}

ps <- cbind(p_76,p_77,p_78,p_79,p_80,p_81,p_82,p_83,p_84,p_85,p_86,p_87,p_88,p_89,p_90,p_91,p_92,p_93,p_94,p_95,p_96,p_97,p_98,p_99)

colnames(ps) <- c("p_76","p_77","p_78","p_79","p_80","p_81","p_82","p_83","p_84","p_85","p_86","p_87","p_88","p_89","p_90","p_91","p_92","p_93","p_94","p_95","p_96","p_97","p_98","p_99")

fig1 <- cbind(fig1,ps)

rm(p_76,p_77,p_78,p_79,p_80,p_81,p_82,p_83,p_84,p_85,p_86,p_87,p_88,p_89,p_90,p_91,p_92,p_93,p_94,p_95,p_96,p_97,p_98,p_99,ps,p)

fig1 <- fig1[!(fig1$x > fig1$n),] #remove rows where x is greater than n         

fig1 <- fig1 %>%
  select(-hold)

# now create a df for plotting with the minimum n for each threshold of P
fig1_plot <- data.frame(matrix(nrow=25,ncol=4))
colnames(fig1_plot) <- c("P_90","P_95","P_99","p")


i = 1
for (col in c("p_75","p_76","p_77","p_78","p_79","p_80","p_81","p_82","p_83","p_84","p_85","p_86","p_87","p_88","p_89","p_90","p_91","p_92","p_93","p_94","p_95","p_96","p_97","p_98","p_99")) {
  figx <- fig1 %>%
  select(n, col) 
  colnames(figx) <- c("n","p")
  fig1_plot[i,1] <- min(figx$n[figx$p > 0.90])
  fig1_plot[i,2] <- min(figx$n[figx$p > 0.95])
  fig1_plot[i,3] <- min(figx$n[figx$p > 0.99])
  i = i + 1
} 

fig1_plot$p <- seq(75,99)

```

## Figure 1. Simulated Replication Reliabilities

```{r fig1_out, warning = F, message = F}
yl <- expression(paste("Number of Replications Required (", italic("n"), ")", sep = ""))
xl <- expression(paste("Binomial Probability that a Single Replication is Accurate (", italic("p"), ")", sep = ""))
P99 <- expression(paste(italic("P"), " > 99% confidence"))
P95 <- expression(paste(italic("P"), " > 95%"))
P90 <- expression(paste(italic("P"), " > 90%"))

reps <- "If the true binamial probability of any given\nreplication being correct is 89% (x-axis) then\nat least 7 independent replications (y-axis) are\nneeded to guarantee that a majority (here at\nleast 4 of these 7) are successful in 99% of\nall potential replication trials"

agg_png(filename = here::here("results","Fig1.png"), res = 144, width = 1000, height = 700)
fig1_plot %>%
  mutate(P_90 = P_90 - 0.05,
         P_95 = P_95 + 0.05) %>% # shift lines slightly as a visual 'dodge'
  ggplot(aes(x = p)) +
  geom_line(aes(y = P_99), color = "#3CBB75FF", size = 1.5, family = "Times New Roman") +
  geom_line(aes(y = P_95), color = "#287D8EFF", size = 1.5, family = "Times New Roman") +
  geom_line(aes(y = P_90), color = "#453781FF", size = 1.5, family = "Times New Roman") +
  # P labels
  annotate("label", x = 83, y = 10, label = P99, color = "#3CBB75FF", fill = "white", family = "Times New Roman") +
  annotate("label", x = 82, y = 6, label = P95, color = "#287D8EFF", fill = "white", family = "Times New Roman") +
  annotate("label", x = 80.5, y = 4, label = P90, color = "#453781FF", fill = "white", family = "Times New Roman") +
  # text box and curved arrow
  geom_curve(
    aes(x = 93, y = 11, xend = 89.1, yend = 7.5),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", angle = 20),
    color = "grey40", curvature = -0.3, lwd = 0.3) +
  annotate("label", x = 98, y = 13, label = reps, color = "grey40", size = 3, hjust = 0, fill = "white", family = "Times New Roman") +
  # add white points on top of lines
  geom_point(aes(y = P_99), color = "white", size = 0.8, family = "Times New Roman") +
  geom_point(aes(y = P_95), color = "white", size = 0.8, family = "Times New Roman") +
  geom_point(aes(y = P_90), color = "white", size = 0.8, family = "Times New Roman") +
  scale_x_reverse() +

  ylim(1,20) +
  labs(y = yl, x = xl) +
  scale_y_continuous(breaks = waiver(), n.breaks = 20) +
  theme_classic() +
  theme(text = element_text(family = "Times New Roman"),
        axis.title.x = element_text(vjust=-1),
        axis.title.y = element_text(vjust=2),
        panel.grid.major = element_line(color = "grey90", linetype = "dashed", size = 0.33))
dev.off()

knitr::include_graphics(here::here("results","Fig1.png"))
```

## Summary Statistics 

```{r team_sums}
cri_sum <- cri_long %>%
  group_by(u_teamid2) %>%
  mutate(Exp = ifelse(Exp1 == "1",1,0)) %>%
  select(verif, exact, deviance_abs, Exp) %>%
  summarise_all(.funs = c(mean))

cri_sum_cur <- cri_cur_long %>%
  group_by(u_teamid2) %>%
  mutate(Exp = ifelse(Exp1 == "1",1,0)) %>%
  select(verif, exact, deviance_abs, Exp) %>%
  mutate(verif_cur = verif,
         exact_cur = exact,
         deviance_cur = deviance_abs) %>%
  select(-c(verif, exact, deviance_abs, Exp)) %>%
  summarise_all(.funs = c(mean))

cri_sums <- left_join(cri_sum, cri_sum_cur, by = "u_teamid2")

cri_sums <- cri_sums %>%
  arrange(Exp, u_teamid2) %>%
  select(u_teamid2, verif, exact, deviance_abs, verif_cur, exact_cur, deviance_cur, Exp) %>%
  mutate(Team = ifelse(u_teamid2 == 591, 59,
                       ifelse(u_teamid2 == 8101, 81, u_teamid2)))

write_csv(cri_sums, file = here::here("results","team_summary.csv"))

# add qualitative categories
qual_out <- read.csv(here::here("results", "qual_out.csv"))
qual_out <- qual_out %>%
  rename(u_teamid2 = Team) # to get unique matches (no repeats)

cri_sums <- cri_sums %>%
  left_join(qual_out, by = "u_teamid2")

cri_sums[is.na(cri_sums)] <- 0
```

## Figure 2. Comparing Replication Outcomes

### Part A. Effect-Level

#### Prep Fig2a Data
```{r fig2prep, warning = F, message = F}
fig2 <- cri_long %>%
  select(verif, exact, deviance_abs, Exp1) %>%
  group_by(Exp1) %>%
  mutate(n = n()) %>%
  summarise_all(.funs = c(mean,sd)) %>%
  mutate(group = ifelse(Exp1 == 1, "Transparent Group", "Opaque Group"),
         version = "Original Results",
         stat = "Verification")

fig2cur <- cri_cur_long %>%
  select(verif, exact, deviance_abs, Exp1) %>%
  group_by(Exp1) %>%
  mutate(n = n()) %>%
  summarise_all(.funs = c(mean,sd)) %>%
  mutate(group = ifelse(Exp1 == 1, "Transparent Group", "Opaque Group"),
         version = "Curated Results",
         stat = "Verification")

fig2 <- rbind(fig2, fig2cur)

fig2[5:8, "verif_fn1"] <- fig2[1:4, "exact_fn1"] # put in long form
fig2[9:12, "verif_fn1"] <- fig2[1:4, "deviance_abs_fn1"] 
fig2[5:8, "verif_fn2"] <- fig2[1:4, "exact_fn2"]
fig2[9:12, "verif_fn2"] <- fig2[1:4, "deviance_abs_fn2"]


fig2[5:8, "stat"] <- "Exact Replication"
fig2[9:12, "stat"] <- "Replication Error"

fig2[5:8, "group"] <- fig2[1:4, "group"]
fig2[9:12, "group"] <- fig2[1:4, "group"]

fig2[5:8, "version"] <- fig2[1:4, "version"]
fig2[9:12, "version"] <- fig2[1:4, "version"]

fig3 <- fig2[9:12,]
fig2 <- fig2[1:8,]

fig2$result <- fig2$verif_fn1*100 # put in % scale
fig2$se <- (fig2$verif_fn2/sqrt(1874))*100 # add standard error in % scale
fig3$result <- fig3$verif_fn1
fig3$se <- fig3$verif_fn2/sqrt(1874)


rm(fig2cur)

f2colors <- c("#482677FF", "#29AF7FFF", "#2D708EFF", "#95D840FF", "#482677FF", "#29AF7FFF", "#2D708EFF", "#95D840FF")
f2colors1 <- c("#482677FF", "#29AF7FFF", "#2D708EFF", "#95D840FF")
fig2$result <- round(fig2$result,1)
```


#### Produce Fig2a
```{r fig2out}
agg_png(here::here("results","Fig2a.png"), height = 700, width = 650, res = 144)
fig2a <- ggplot(data = fig2) +
  geom_col(aes(y = result, x = c(1,2,3,4,5.5,6.5,7.5,8.5), fill = interaction(group, version))) +
  geom_errorbar(aes(ymin = result-se, ymax = result+se, x = c(1,2,3,4,5.5,6.5,7.5,8.5),), color = "grey50", width = 0.5) +
  scale_fill_manual(values = f2colors,
                    labels = c(" \nCURATED\n   Opaque\n   Group\n ",
                               " \nCURATED\n   Transparent\n   Group\n ",
                               " \nORIGINAL\n   Opaque\n   Group\n ",
                               " \nORIGINAL\n   Transparent\n   Group\n "),
                    guide = guide_legend(reverse = TRUE)) +
  geom_vline(aes(xintercept = 4.75)) +
  #annotate("text", x = 2.5, y = 34, label = "Verification\n(same sign)", angle = 90) +
    geom_richtext(aes(x = 2.5, y = 32, label = "VERIFICATION<br>"), 
                angle = 90, 
                label.padding = unit(8, "pt"), family = "Times New Roman"
                ) +
  geom_richtext(aes(x = 2.5, y = 34, label = "<p style = 'font-size:10px; text-align:justify'><i>(same sign)<i></p>"), 
                angle = 90, fill = NA, label.color = NA, family = "Times New Roman") +
  geom_richtext(aes(x = 7, y = 33, label = "EXACT<br>REPLICATION<br>"), 
                angle = 90, 
                label.padding = unit(8, "pt"), family = "Times New Roman") +
  geom_richtext(aes(x = 7, y = 37, label = "<p style = 'font-size:10px; text-align:justify'><i>(within 0.01)</i></p>"), 
                angle = 90, fill = NA, label.color = NA, family = "Times New Roman") +
  geom_text(aes(y = result - c(7,7,7,7,7,-7,7,-7), x = c(1,2,3,4,5.5,6.5,7.5,8.5), label = fig2$result), family = "Times New Roman") +
  ylab("Percent of Replicated Effects") +
  xlab(" ") +
  labs(title = "A. Effect-Level Results, N = 3,742") +
  coord_flip(ylim = c(25,100), clip = "on") +
  scale_x_reverse() +
  theme_classic() +
  theme(text = element_text(family = "Times New Roman"),
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 11),
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0))
fig2a
dev.off()

knitr::include_graphics(here::here("results","Fig2a.png"))
```
### Part B. ICC

```{r fig2b_icc}
# calculate ICC/rho

#1. estimate empty model
m1t <- lmer(verif ~ (1|u_teamid), data = subset(cri_long, cri_long$Exp1==1))
m1o <- lmer(verif ~ (1|u_teamid), data = subset(cri_long, cri_long$Exp1==0))
m2t <- lmer(verif ~ (1|u_teamid), data = subset(cri_cur_long, cri_cur_long$Exp1==1))
m2o <- lmer(verif ~ (1|u_teamid), data = subset(cri_cur_long, cri_cur_long$Exp1==0))
m3t <- lmer(exact ~ (1|u_teamid), data = subset(cri_long, cri_long$Exp1==1))
m3o <- lmer(exact ~ (1|u_teamid), data = subset(cri_long, cri_long$Exp1==0))
m4t <- lmer(exact ~ (1|u_teamid), data = subset(cri_cur_long, cri_cur_long$Exp1==1))
m4o <- lmer(exact ~ (1|u_teamid), data = subset(cri_cur_long, cri_cur_long$Exp1==0))
m5t <- lmer(deviance_abs ~ (1|u_teamid), data = subset(cri_long, cri_long$Exp1==1))
m5o <- lmer(deviance_abs ~ (1|u_teamid), data = subset(cri_long, cri_long$Exp1==0))
m6t <- lmer(deviance_abs ~ (1|u_teamid), data = subset(cri_cur_long, cri_cur_long$Exp1==1))
m6o <- lmer(deviance_abs ~ (1|u_teamid), data = subset(cri_cur_long, cri_cur_long$Exp1==0))

#2. icc
a <- icc_specs(m1t) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Original, transparent, verification") %>%
  subset(grp == "u_teamid")
aa <- icc_specs(m1o) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Original, opaque, verification") %>%
  subset(grp == "u_teamid")
b <- icc_specs(m2t) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Curated, transparent, verification") %>%
  subset(grp == "u_teamid")
bb <- icc_specs(m2o) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Curated, opaque, verification") %>%
  subset(grp == "u_teamid")
c <- icc_specs(m3t) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Original, transparent, exact replication") %>%
  subset(grp == "u_teamid")
cc <- icc_specs(m3o) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Original, opaque, exact replication") %>%
  subset(grp == "u_teamid")
d <- icc_specs(m4t) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Curated, transparent, exact replication") %>%
  subset(grp == "u_teamid")
dd <- icc_specs(m4o) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Curated, opaque, exact replication") %>%
  subset(grp == "u_teamid")
e <- icc_specs(m5t) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Original, transparent, replication error") %>%
  subset(grp == "u_teamid")
ee <- icc_specs(m5o) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Original, opaque, replication error") %>%
  subset(grp == "u_teamid")
f <- icc_specs(m6t) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Curated, transparent, replication error") %>%
  subset(grp == "u_teamid")
ff <- icc_specs(m6o) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(test = "Curated, opaque, replication error") %>%
  subset(grp == "u_teamid")

icc_out <- rbind(a,aa,b,bb,c,cc,d,dd,e,ee,f,ff)
rm(a,aa,b,bb,c,cc,d,dd,e,ee,f,ff)
```

### Part C. Team Level

#### Prep Fig2b Data
```{r fig2b_teamsummaries}
fig2b <- cri_long %>%
  select(verif, exact, deviance_abs, Exp1, u_teamid2) %>%
  subset(u_teamid2 != 591 & u_teamid2 != 8101) %>%
  group_by(Exp1,u_teamid2) %>%
  mutate(n = n()) %>%
  summarise_all(.funs = c(mean,sd), na.rm = T) %>%
  mutate(verif = ifelse(verif_fn1 >= .95, 1, 0), # if 95% or more of team results are verif then team-level verification = 1
         exact = ifelse(exact_fn1 >= .95, 1, 0), # same criteria as verif
         deviance = deviance_abs_fn1
         ) %>%
  ungroup()

# collapse team-level scores
fig2b_c <- fig2b %>%
  select(verif, exact, deviance, Exp1) %>%
  group_by(Exp1) %>%
  mutate(n = n()) %>%
  summarise_all(.funs = c(mean,sd)) %>%
  mutate(group = ifelse(Exp1 == 1, "Transparent Group", "Opaque Group"),
         version = "Original Results",
         stat = "Verification")
  
  

fig2bcur <- cri_cur_long %>%
  select(verif, exact, deviance_abs, Exp1, u_teamid2) %>%
  group_by(Exp1,u_teamid2) %>%
  mutate(n = n()) %>%
  summarise_all(.funs = c(mean,sd), na.rm = T) %>%
  mutate(verif = ifelse(verif_fn1 >= .95, 1, 0), # if 95% or more of team results are verif then team-level verification = 1
         exact = ifelse(exact_fn1 >= .95, 1, 0), # same criteria as verif
         deviance = deviance_abs_fn1
         ) %>%
  ungroup()

# collapse team-level scores
fig2bcur_c <- fig2bcur %>%
  subset(u_teamid2 != 591 & u_teamid2 != 8101) %>%
  select(verif, exact, deviance, Exp1) %>%
  group_by(Exp1) %>%
  mutate(n = n()) %>%
  summarise_all(.funs = c(mean,sd), na.rm = T) %>%
  mutate(group = ifelse(Exp1 == 1, "Transparent Group", "Opaque Group"),
         version = "Curated Results",
         stat = "Verification")

fig2b <- rbind(fig2b_c, fig2bcur_c)
#rm(fig2b_c, fig2bcur, fig2bcur_c)

fig2b[5:8, "verif_fn1"] <- fig2b[1:4, "exact_fn1"] # put in long form
fig2b[9:12, "verif_fn1"] <- fig2b[1:4, "deviance_fn1"] 
fig2b[5:8, "verif_fn2"] <- fig2b[1:4, "exact_fn2"]
fig2b[9:12, "verif_fn2"] <- fig2b[1:4, "deviance_fn2"]


fig2b[5:8, "stat"] <- "Exact Replication"
fig2b[9:12, "stat"] <- "Replication Error"

fig2b[5:8, "group"] <- fig2b[1:4, "group"]
fig2b[9:12, "group"] <- fig2b[1:4, "group"]

fig2b[5:8, "version"] <- fig2b[1:4, "version"]
fig2b[9:12, "version"] <- fig2b[1:4, "version"]

fig3b <- fig2b[9:12,]
fig2b <- fig2b[1:8,]
fig2b$result <- fig2b$verif_fn1*100 # put in % scale
fig2b$se <- (fig2b$verif_fn2/sqrt(1874))*100 # add standard error in % scale
fig3b$result <- fig3b$verif_fn1
fig3b$se <- (fig3b$verif_fn2/sqrt(1874))



fig2b$result <- round(fig2b$result,1)

```

#### Produce Fig2b

```{r fig2bout}
agg_png(here::here("results","Fig2b.png"), height = 700, width = 475, res = 144)
fig2bb <- ggplot(data = fig2b) +
  geom_col(aes(y = result, x = c(1,2,3,4,5.5,6.5,7.5,8.5), fill = interaction(group, version))) +
  geom_errorbar(aes(ymin = result-se, ymax = result+se, x = c(1,2,3,4,5.5,6.5,7.5,8.5),), color = "grey50", width = 0.5) +
  scale_fill_manual(values = f2colors) +
  geom_vline(aes(xintercept = 4.75)) +
  geom_richtext(aes(x = 2.5, y = 28, label = "VERIFICATION<br>"), 
                angle = 90, 
                label.padding = unit(8, "pt"), family = "Times New Roman"
                ) +
  geom_richtext(aes(x = 2.5, y = 32.5, label = "<p style = 'font-size:10px; text-align:justify'><i>(95%+ of within</i><br><i>team effects)<i></p>"), 
                angle = 90, fill = NA, label.color = NA, family = "Times New Roman") +
  geom_richtext(aes(x = 6.9, y = 32, label = "EXACT<br>REPLICATION<br>"), 
                angle = 90, 
                label.padding = unit(8, "pt"), family = "Times New Roman") +
  geom_richtext(aes(x = 6.9, y = 38, label = "<p style = 'font-size:10px; text-align:justify'><i>(95%+ of within</i><br><i>team effects</i>)"), 
                angle = 90, fill = NA, label.color = NA, family = "Times New Roman") +
  
  # add ICC to plot
  # title
  annotate("text", x = 0.7, y = 92, parse = T, label = expression(paste("Between ", sigma^{2})), size = 3, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 1, y = 92, label = paste0(round(icc_out$percent[1],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 2, y = 92, label = paste0(round(icc_out$percent[2],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 3, y = 92, label = paste0(round(icc_out$percent[3],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 4, y = 92, label = paste0(round(icc_out$percent[4],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 5.5, y = 92, label = paste0(round(icc_out$percent[5],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 6.5, y = 92, label = paste0(round(icc_out$percent[6],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 7.5, y = 92, label = paste0(round(icc_out$percent[7],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 8.5, y = 92, label = paste0(round(icc_out$percent[8],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  # add percentages
  geom_text(aes(y = result - c(7,7,7,7,7,-6,7,-7), x = c(1,2,3,4,5.5,6.5,7.5,8.5), label = fig2b$result), family = "Times New Roman") +
  ylab("Percent of Teams") +
  xlab(" ") +
  labs(title = "B. Team-Level Results, N = 85") +
  coord_flip(ylim = c(5,100), clip = "on") +
  scale_x_reverse() +
  theme_classic() +
  theme(text = element_text(family = "Times New Roman"),
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 11),
        legend.position = "none",
        plot.title = element_text(hjust = 0))
fig2bb
dev.off()

knitr::include_graphics(here::here("results","Fig2b.png"))
```
### Figure 2 Combined

This chunk is no longer used because the ggarrange package doesn't deal with Times New Roman very well.
```{r fig2final}
agg_png(here::here("results","Fig2.png"), width = 1300, height = 800, res = 144)
ggarrange(fig2a,fig2bb, ncol = 2, nrow = 1, widths = c(1.4,1))
dev.off()

knitr::include_graphics(here::here("results", "Fig2.png"))
```
### Fig 2C Effect-Level

```{r ddeviance_fig2effect}
agg_png(here::here("results","Fig2c1.png"), height = 350, width = 475, res = 144)

fig2c1 <- ggplot(data = fig3) +
  geom_col(aes(y = result, x = c(1,2,3,4), fill = interaction(group, version))) +
  geom_errorbar(aes(ymin = result-se, ymax = result+se, x = c(1,2,3,4),), color = "grey50", width = 0.5) +
  scale_fill_manual(values = f2colors1,
                    guide = guide_legend(reverse = TRUE)) +
    geom_richtext(aes(x = 2.5, y = 0.04, label = "REPLICATION<br>ERROR<br>"), 
                angle = 90, 
                label.padding = unit(8, "pt"), family = "Times New Roman"
                ) +
  geom_richtext(aes(x = 2.5, y = 0.044, label = "<p style = 'font-size:10px; text-align:justify'><i>(abs. difference)<i></p>"), 
                angle = 90, fill = NA, label.color = NA, family = "Times New Roman") +
  geom_text(aes(y = result - c(0.007,0.01,-0.007,0.007), x = c(1,2,3,4), label = round(fig3$result,3)), family = "Times New Roman") +
  ylab("Absolute Difference from Original Effect") +
  xlab(" ") +
  coord_flip(ylim = c(0.005,0.08), clip = "on") +
  scale_x_reverse() +
  theme_classic() +
  theme(text = element_text(family = "Times New Roman"),
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 11),
        legend.position = "none",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0))
fig2c1
dev.off()

knitr::include_graphics(here::here("results","Fig2c1.png"))
```


### Fig 2C Team-Level

```{r deviance_fig2}
agg_png(here::here("results","Fig2c2.png"), height = 350, width = 475, res = 144)
fig2c2 <- ggplot(data = fig3b) +
  geom_col(aes(y = result, x = c(1,2,3,4), fill = interaction(group, version))) +
  geom_errorbar(aes(ymin = result-se, ymax = result+se, x = c(1,2,3,4),), color = "grey50", width = 0.5) +
  scale_fill_manual(values = f2colors1,
                    guide = guide_legend(reverse = TRUE)) +
    geom_richtext(aes(x = 2.5, y = 0.04, label = "REPLICATION<br>ERROR<br>"), 
                angle = 90, 
                label.padding = unit(8, "pt"), family = "Times New Roman"
                ) +
  geom_richtext(aes(x = 2.5, y = 0.045, label = "<p style = 'font-size:10px; text-align:justify'><i>(between team avg.)<i></p>"), 
                angle = 90, fill = NA, label.color = NA, family = "Times New Roman") +
  geom_text(aes(y = result - c(0.007,0.012,-0.007,0.0085), x = c(1,2,3,4), label = round(fig3b$result,3)), family = "Times New Roman") +
  ylab("Average of Team-Level Error") +
  xlab(" ") +
  coord_flip(ylim = c(0.005,0.09), clip = "on") +
  scale_x_reverse() +

  # add ICC to plot
  annotate("text", x = 1, y = 0.085, label = paste0(round(icc_out$percent[9],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 2, y = 0.085, label = paste0(round(icc_out$percent[10],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 3, y = 0.085, label = paste0(round(icc_out$percent[11],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  annotate("text", x = 4, y = 0.085, label = paste0(round(icc_out$percent[12],0),"%"), size = 3, hjust = 0, color = "grey20", family = "Times New Roman") +
  
  theme_classic() +
  theme(text = element_text(family = "Times New Roman"),
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_text(size = 11),
        legend.position = "none",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0))
 
fig2c2
dev.off()

knitr::include_graphics(here::here("results","Fig2c2.png"))
```


## Table 1

### Setup

```{r table2}

# start with descriptive table

desc <- as.data.frame(matrix(nrow = 24, ncol = 8))

desc[1,] <- c("","","Team-Level","","","Effect-Level","","")

desc[2,] <- c("Variables","Measurement","Transparent","Opaque", "Pooled", "Transparent","Opaque", "Pooled")

desc[,1] <- c("", "Variables","Cases", "Raw Replication Results", "Verification", "Exact Verification", "Deviance", "Curated Replication Results", "Verification", "Exact Verification", "Deviance", "Independent Variables", "Stata", "Sociology Degree", "Stats-Skill", "Difficulty", "Team Size", "Qualitative Categories", "Mistake", "Procedural", "Mistake-Procedural", "Missing Component", "Interpretational", "Questionable Methods Competencies")

desc[,2] <- c("", "Measurement","", "", "same direction =1","identical at two decimals =1", "absolute difference with original","", "same direction =1","identical at two decimals =1", "absolute difference with original","", "other software =0","other degrees =0","4-question scale, stdzd,","1-question, stdzd.","1-3 persons", "", "see text", "see text", "see text", "see text", "see text", "see text")


# fill in transparent group results

desc[3:24,6] <- c(sum(!is.na(cri_long$verif[cri_long$Exp1 == 1])),"", 
                  mean(cri_long$verif[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$exact[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$deviance_abs[cri_long$Exp1 == 1], na.rm = T),
                  "",
                  mean(cri_cur_long$verif[cri_cur_long$Exp1 == 1], na.rm = T),
                  mean(cri_cur_long$exact[cri_cur_long$Exp1 == 1], na.rm = T),
                  mean(cri_cur_long$deviance_abs[cri_cur_long$Exp1 == 1], na.rm = T),
                  "",
                  mean(cri_long$stata[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$degree_soc[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$stat_skill[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$numinteam[cri_long$Exp1 == 1], na.rm = T),
                  mean(cri_long$difficult[cri_long$Exp1 == 1], na.rm = T),
                  "",
                  length(cri_sums$Mistake[cri_sums$Exp == 1 & cri_sums$Mistake != 0])/length(cri_sums$Mistake[cri_sums$Exp == 1]),
                  length(cri_sums$Procedural[cri_sums$Exp == 1 & cri_sums$Procedural != 0])/length(cri_sums$Procedural[cri_sums$Exp == 1]),
                  length(cri_sums$Mistake_Procedural[cri_sums$Exp == 1 & cri_sums$Mistake_Procedural != 0])/length(cri_sums$Mistake_Procedural[cri_sums$Exp == 1]),
                  length(cri_sums$Missing_Parts[cri_sums$Exp == 1 & cri_sums$Missing_Parts != 0])/length(cri_sums$Missing_Parts[cri_sums$Exp == 1]),
                  length(cri_sums$Interpretational[cri_sums$Exp == 1 & cri_sums$Interpretational != 0])/length(cri_sums$Interpretational[cri_sums$Exp == 1]),
                  length(cri_sums$Questionable_Skills[cri_sums$Exp == 1 & cri_sums$Questionable_Skills != 0])/length(cri_sums$Questionable_Skills[cri_sums$Exp == 1])
                  )

# opaque

desc[3:24,7] <- c(sum(!is.na(cri_long$verif[cri_long$Exp1 == 0])),"", 
                  mean(cri_long$verif[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$exact[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$deviance_abs[cri_long$Exp1 == 0], na.rm = T),
                  "",
                  mean(cri_cur_long$verif[cri_cur_long$Exp1 == 0], na.rm = T),
                  mean(cri_cur_long$exact[cri_cur_long$Exp1 == 0], na.rm = T),
                  mean(cri_cur_long$deviance_abs[cri_cur_long$Exp1 == 0], na.rm = T),
                  "",
                  mean(cri_long$stata[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$degree_soc[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$stat_skill[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$numinteam[cri_long$Exp1 == 0], na.rm = T),
                  mean(cri_long$difficult[cri_long$Exp1 == 0], na.rm = T),
                  "",
                  length(cri_sums$Mistake[cri_sums$Exp == 0 & cri_sums$Mistake != 0])/length(cri_sums$Mistake[cri_sums$Exp == 0]),
                  length(cri_sums$Procedural[cri_sums$Exp == 0 & cri_sums$Procedural != 0])/length(cri_sums$Procedural[cri_sums$Exp == 0]),
                  length(cri_sums$Mistake_Procedural[cri_sums$Exp == 0 & cri_sums$Mistake_Procedural != 0])/length(cri_sums$Mistake_Procedural[cri_sums$Exp == 0]),
                  length(cri_sums$Missing_Parts[cri_sums$Exp == 0 & cri_sums$Missing_Parts != 0])/length(cri_sums$Missing_Parts[cri_sums$Exp == 0]),
                  length(cri_sums$Interpretational[cri_sums$Exp == 0 & cri_sums$Interpretational != 0])/length(cri_sums$Interpretational[cri_sums$Exp == 0]),
                  length(cri_sums$Questionable_Skills[cri_sums$Exp == 0 & cri_sums$Questionable_Skills != 0])/length(cri_sums$Questionable_Skills[cri_sums$Exp == 0])
                  )

# pooled

desc[3:24,8] <- c(sum(!is.na(cri_long$verif)),"", 
                  mean(cri_long$verif, na.rm = T),
                  mean(cri_long$exact, na.rm = T),
                  mean(cri_long$deviance_abs, na.rm = T),
                  "",
                  mean(cri_cur_long$verif, na.rm = T),
                  mean(cri_cur_long$exact, na.rm = T),
                  mean(cri_cur_long$deviance_abs, na.rm = T),
                  "",
                  mean(cri_long$stata, na.rm = T),
                  mean(cri_long$degree_soc, na.rm = T),
                  mean(cri_long$stat_skill, na.rm = T),
                  mean(cri_long$numinteam, na.rm = T),
                  mean(cri_long$difficult, na.rm = T),
                  "",
                  length(unique(cri_sums$Team[cri_sums$Mistake != 0]))/85,
                  length(unique(cri_sums$Team[cri_sums$Procedural != 0]))/85,
                  length(unique(cri_sums$Team[cri_sums$Mistake_Procedural != 0]))/85,
                  length(unique(cri_sums$Team[cri_sums$Missing_Parts != 0]))/85,
                  length(unique(cri_sums$Team[cri_sums$Interpretational != 0]))/85,
                  length(unique(cri_sums$Team[cri_sums$Questionable_Skills != 0]))/85
                  )
cri_long_pool <- cri_long %>%
    ungroup() %>%
  group_by(u_teamid2) %>%
  select(verif, exact, deviance_abs) %>%
  summarise_all(.funs = c("mean", "sd")) %>%
  ungroup() %>%
  select(-u_teamid2) %>%
  summarise_all(.funs = c("mean", "sd"))

cri_long_pool_t <- cri_long %>%
    ungroup() %>%
  subset(Exp1 == 1) %>%
  group_by(u_teamid2) %>%
  select(verif, exact, deviance_abs) %>%
  summarise_all(.funs = c("mean", "sd")) %>%
  ungroup() %>%
  select(-u_teamid2) %>%
  summarise_all(.funs = c("mean", "sd"))

cri_long_pool_o <- cri_long %>%
    ungroup() %>%
  subset(Exp1 == 0) %>%
  group_by(u_teamid2) %>%
  select(verif, exact, deviance_abs) %>%
  summarise_all(.funs = c("mean", "sd")) %>%
  ungroup() %>%
  select(-u_teamid2) %>%
  summarise_all(.funs = c("mean", "sd"))

cri_long_cur_pool <- cri_cur_long %>%
    ungroup() %>%
  group_by(u_teamid2) %>%
  select(verif, exact, deviance_abs) %>%
  summarise_all(.funs = c("mean", "sd")) %>%
  ungroup() %>%
  select(-u_teamid2) %>%
  summarise_all(.funs = c("mean", "sd"))

cri_long_cur_pool_t <- cri_cur_long %>%
    ungroup() %>%
  subset(Exp1 == 1) %>%
  group_by(u_teamid2) %>%
  select(verif, exact, deviance_abs) %>%
  summarise_all(.funs = c("mean", "sd")) %>%
  ungroup() %>%
  select(-u_teamid2) %>%
  summarise_all(.funs = c("mean", "sd"))

cri_long_cur_pool_o <- cri_cur_long %>%
    ungroup() %>%
  subset(Exp1 == 0) %>%
  group_by(u_teamid2) %>%
  select(verif, exact, deviance_abs) %>%
  summarise_all(.funs = c("mean", "sd")) %>%
  ungroup() %>%
  select(-u_teamid2) %>%
  summarise_all(.funs = c("mean", "sd"))

# team-level

desc[3,3:5] <- c(39,46,85)
desc[5:7,5] <- t(cri_long_pool[1,1:3])
desc[5:7,3] <- t(cri_long_pool_t[1,1:3])
desc[5:7,4] <- t(cri_long_pool_o[1,1:3])

desc[9:11,5] <- t(cri_long_cur_pool[1,1:3])
desc[9:11,3] <- t(cri_long_cur_pool_t[1,1:3])
desc[9:11,4] <- t(cri_long_cur_pool_o[1,1:3])

write.csv(desc, file = here::here("results","Tbl2.csv"))

```

## Colophon

```{r session}
sessionInfo()
```




